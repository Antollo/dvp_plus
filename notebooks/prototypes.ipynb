{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90d55f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from kornia.geometry.transform import rotate\n",
    "from lcmr_ext.encoder.dino_v2_encoder import DinoV2Encoder\n",
    "from lcmr_ext.loss import CombinedLoss, EfdRegularizerLoss, ImageMaeLoss\n",
    "from lcmr_ext.modeler import ConditionalDETRModeler, EfdModuleConfig, EfdModuleMode, ModelerConfig\n",
    "from lcmr_ext.modeler.efd_module import plot_prototypes\n",
    "from lcmr_ext.renderer.renderer2d import PyTorch3DRenderer2D\n",
    "from lcmr_ext.utils import optimize_params\n",
    "from lcmr_ext.utils.sample_efd import ellipse_efd, heart_efd, square_efd\n",
    "from skimage.draw import polygon2mask\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers.models.conditional_detr import ConditionalDetrConfig\n",
    "\n",
    "from lcmr.dataset import DatasetOptions, EfdGeneratorOptions, RandomDataset\n",
    "from lcmr.grammar.scene_data import SceneData\n",
    "from lcmr.reconstruction_model import ReconstructionModel\n",
    "from lcmr.utils.colors import colors\n",
    "from lcmr.utils.elliptic_fourier_descriptors import reconstruct_contour\n",
    "from lcmr.utils.presentation import display_img, make_img_grid\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "raster_size = (128, 128)\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "show_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c6e8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "    \n",
    "choices = torch.cat([heart_efd()[None], square_efd()[None], ellipse_efd()[None]], dim=0)\n",
    "\n",
    "train_options = DatasetOptions(\n",
    "    raster_size=raster_size,\n",
    "    n_samples=50_000,\n",
    "    n_objects=4,\n",
    "    Renderer=PyTorch3DRenderer2D,\n",
    "    renderer_device=device,\n",
    "    n_jobs=1,\n",
    "    return_images=True,\n",
    "    efd_options=EfdGeneratorOptions(choices=choices),\n",
    ")\n",
    "\n",
    "val_options = DatasetOptions(\n",
    "    raster_size=raster_size,\n",
    "    n_samples=5_000,\n",
    "    n_objects=4,\n",
    "    Renderer=PyTorch3DRenderer2D,\n",
    "    renderer_device=device,\n",
    "    n_jobs=1,\n",
    "    return_images=True,\n",
    "    efd_options=EfdGeneratorOptions(choices=choices),\n",
    ")\n",
    "\n",
    "test_options = DatasetOptions(\n",
    "    raster_size=raster_size,\n",
    "    n_samples=5_000,\n",
    "    n_objects=4,\n",
    "    Renderer=PyTorch3DRenderer2D,\n",
    "    renderer_device=device,\n",
    "    n_jobs=1,\n",
    "    return_images=True,\n",
    "    efd_options=EfdGeneratorOptions(choices=choices),\n",
    ")\n",
    "\n",
    "train_dataset = RandomDataset(train_options)\n",
    "val_dataset = RandomDataset(val_options)\n",
    "test_dataset = RandomDataset(test_options)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "189cf47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True, collate_fn=train_dataset.collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=False, collate_fn=val_dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6531854",
   "metadata": {},
   "outputs": [],
   "source": [
    "renderer = PyTorch3DRenderer2D(raster_size, background_color=colors.black, return_alpha=True, n_verts=64, device=device)\n",
    "\n",
    "encoder = DinoV2Encoder(input_size=(126, 126)).to(device)\n",
    "modeler = ConditionalDETRModeler(\n",
    "    config=ModelerConfig(\n",
    "        encoder_feature_dim=768,\n",
    "        use_single_scale=True,\n",
    "        use_confidence=True,\n",
    "        efd_module_config=EfdModuleConfig(order=16, num_prototypes=3, mode=EfdModuleMode.PrototypeAttention),\n",
    "    ),\n",
    "    detr_config=ConditionalDetrConfig(num_queries=8, dropout=0),\n",
    ").to(device)\n",
    "\n",
    "model = ReconstructionModel(encoder, modeler, renderer)\n",
    "\n",
    "lr = 0.0001\n",
    "optimizer = torch.optim.Adam(list(modeler.parameters()), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953fc005",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"./GP/model_4.pt\", weights_only=False).state_dict()  \n",
    "model.modeler.load_state_dict(state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7caad0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70434b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = next(iter(train_dataloader)).to(device)\n",
    "with torch.no_grad():\n",
    "    pred: SceneData = model(target.image_rgb, render=False)\n",
    "    pred.scene.layer.object.efd[:] = ellipse_efd(modeler.to_efd.config.order)[None, None, None, ...]\n",
    "    pred.scene.layer.object.appearance.confidence[:] = pred.scene.layer.object.appearance.confidence.round()\n",
    "    pred = renderer.render(pred.scene)\n",
    "    img_grid = make_img_grid((pred.image_rgb_top, target.image_rgb_top))\n",
    "    pred.scene = pred.scene.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6829301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_contours(contours, resolution: int = 64):\n",
    "    device = contours.device\n",
    "    contours = (contours * resolution / 2 + resolution / 2).detach().cpu().numpy()\n",
    "    masks = torch.from_numpy(np.array([polygon2mask((resolution, resolution), contour) for contour in contours])).to(device)\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0059e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = CombinedLoss((0.01, EfdRegularizerLoss()), (1.0, ImageMaeLoss())).to(device)\n",
    "\n",
    "for i in range(10):\n",
    "    optimize_params(pred, target, renderer, loss_func=loss_func, params=pred.scene.fields[\"tsrcb\"], show_progress=False, lr=0.05, epochs=100)\n",
    "    optimize_params(pred, target, renderer, loss_func=loss_func, params=pred.scene.fields[\"tsrcbe\"], show_progress=False, lr=0.0005, epochs=100)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = renderer.render(pred.scene)\n",
    "        img_grid = make_img_grid((pred.image_rgb_top, target.image_rgb_top))\n",
    "        display_img(img_grid)\n",
    "    \n",
    "    prototypes_mask = pred.scene.layer.object.appearance.confidence.flatten() > 0.5\n",
    "    prototypes = pred.scene.layer.object.efd.flatten(0, 2)[prototypes_mask]\n",
    "\n",
    "    contours = draw_contours(reconstruct_contour(prototypes), resolution=128).to(torch.float32)\n",
    "    precomputed = torch.cdist(contours.flatten(-2, -1), contours.flatten(-2, -1), p=2)\n",
    "    for a in range(0, 360, 1):\n",
    "        rotated = rotate(contours[..., None].permute(0, 3, 1, 2), angle=torch.tensor([a], device=device, dtype=torch.float32)).permute(0, 2, 3, 1)[..., 0]\n",
    "        precomputed = torch.minimum(precomputed, torch.cdist(contours.flatten(-2, -1), rotated.flatten(-2, -1), p=2))\n",
    "    precomputed.fill_diagonal_(0)\n",
    "\n",
    "    silhouette_scores = []\n",
    "    clustering_temp = []\n",
    "    k_range = range(2, 9)\n",
    "    for k in k_range:\n",
    "        print(f\"Running KMedoids for k={k}...\")\n",
    "        clustering = KMedoids(metric=\"precomputed\", init=\"k-medoids++\", n_clusters=k, method=\"pam\", max_iter=1200).fit(precomputed.cpu())\n",
    "        score_s = silhouette_score(precomputed.cpu(), clustering.labels_, metric=\"precomputed\")\n",
    "        silhouette_scores.append(score_s)\n",
    "        clustering_temp.append(clustering)\n",
    "    \n",
    "    idx = np.argmax(silhouette_scores)\n",
    "    if i < 5:\n",
    "        idx += 1\n",
    "    idx = min(idx, len(k_range) - 1)\n",
    "    print(f\"Optimal k based on Silhouette Score (peak): {k_range[idx]}\")\n",
    "    \n",
    "    clustering = clustering_temp[idx]\n",
    "\n",
    "    indices = torch.from_numpy(clustering.medoid_indices_).to(device)\n",
    "    labels = torch.from_numpy(clustering.labels_).to(device)\n",
    "\n",
    "    plot_prototypes(prototypes[indices])\n",
    "    \n",
    "    pred.scene.layer.object.efd.flatten(0, 2)[prototypes_mask] = prototypes[indices][labels]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred = renderer.render(pred.scene)\n",
    "        img_grid = make_img_grid((pred.image_rgb_top, target.image_rgb_top))\n",
    "        display_img(img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e634a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(prototypes[indices], \"prototypes.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab82abac",
   "metadata": {},
   "outputs": [],
   "source": [
    "prototypes = torch.load(\"prototypes.pt\")\n",
    "plot_prototypes(prototypes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
