{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c0e686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from collections import defaultdict\n",
    "from contextlib import nullcontext\n",
    "from glob import glob\n",
    "from io import BytesIO\n",
    "\n",
    "import cairosvg\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from bs4 import BeautifulSoup\n",
    "from kornia.filters import canny, gaussian_blur2d\n",
    "from lcmr_ext.encoder.dino_v2_encoder import DinoV2Encoder\n",
    "from lcmr_ext.loss import CombinedLoss, EfdRegularizerLoss, ImageMaeLoss, ImageMseLoss, SceneLoss\n",
    "from lcmr_ext.modeler import ConditionalDETRModeler, EfdModuleConfig, EfdModuleMode, ModelerConfig\n",
    "from lcmr_ext.renderer.renderer2d import PyTorch3DRenderer2D\n",
    "from lcmr_ext.utils import optimize_params\n",
    "from lcmr_ext.utils.sample_efd import ellipse_efd, heart_efd, square_efd\n",
    "from object_centric_library.evaluation.metrics.ari import ari\n",
    "from omegaconf import OmegaConf\n",
    "from PIL import Image\n",
    "from skimage import measure\n",
    "from torch.nn.functional import l1_loss, mse_loss\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.aggregation import MeanMetric\n",
    "from torchmetrics.classification import BinaryJaccardIndex\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "from torchvision.transforms.functional import pil_to_tensor\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "from transformers.models.conditional_detr import ConditionalDetrConfig\n",
    "\n",
    "from lcmr.dataset import DatasetOptions, EfdGeneratorOptions, RandomDataset\n",
    "from lcmr.grammar import Scene\n",
    "from lcmr.grammar.scene_data import SceneData\n",
    "from lcmr.grammar.shapes import Shape2D\n",
    "from lcmr.reconstruction_model import ReconstructionModel\n",
    "from lcmr.renderer.renderer2d import OpenGLRenderer2D\n",
    "from lcmr.utils.colors import colors\n",
    "from lcmr.utils.elliptic_fourier_descriptors import EfdGeneratorOptions\n",
    "from lcmr.utils.presentation import display_img, make_img_grid\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "raster_size = (128, 128)\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfebbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "    \n",
    "choices = torch.cat([heart_efd()[None], square_efd()[None], ellipse_efd()[None]], dim=0)\n",
    "\n",
    "train_options = DatasetOptions(\n",
    "    raster_size=raster_size,\n",
    "    n_samples=50_000,\n",
    "    n_objects=4,\n",
    "    Renderer=PyTorch3DRenderer2D,\n",
    "    renderer_device=device,\n",
    "    n_jobs=1,\n",
    "    return_images=False,\n",
    "    efd_options=EfdGeneratorOptions(choices=choices),\n",
    ")\n",
    "\n",
    "val_options = DatasetOptions(\n",
    "    raster_size=raster_size,\n",
    "    n_samples=5_000,\n",
    "    n_objects=4,\n",
    "    Renderer=PyTorch3DRenderer2D,\n",
    "    renderer_device=device,\n",
    "    n_jobs=1,\n",
    "    return_images=True,\n",
    "    efd_options=EfdGeneratorOptions(choices=choices),\n",
    ")\n",
    "\n",
    "test_options = DatasetOptions(\n",
    "    raster_size=raster_size,\n",
    "    n_samples=5_000,\n",
    "    n_objects=4,\n",
    "    Renderer=PyTorch3DRenderer2D,\n",
    "    renderer_device=device,\n",
    "    n_jobs=1,\n",
    "    return_images=True,\n",
    "    efd_options=EfdGeneratorOptions(choices=choices),\n",
    ")\n",
    "\n",
    "train_dataset = RandomDataset(train_options)\n",
    "val_dataset = RandomDataset(val_options)\n",
    "test_dataset = RandomDataset(test_options)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453f9f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True, collate_fn=train_dataset.collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True, collate_fn=val_dataset.collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True, collate_fn=test_dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f52517",
   "metadata": {},
   "outputs": [],
   "source": [
    "renderer = PyTorch3DRenderer2D(raster_size, background_color=colors.black, return_alpha=True, n_verts=64, device=device)\n",
    "encoder = DinoV2Encoder(input_size=(126, 126)).to(device)\n",
    "modeler = ConditionalDETRModeler(\n",
    "    config=ModelerConfig(\n",
    "        encoder_feature_dim=768,\n",
    "        use_single_scale=True,\n",
    "        use_confidence=True,\n",
    "        efd_module_config=EfdModuleConfig(order=16, num_prototypes=3, mode=EfdModuleMode.PrototypeAttention),\n",
    "    ),\n",
    "    detr_config=ConditionalDetrConfig(num_queries=8, dropout=0),\n",
    ").to(device)\n",
    "\n",
    "model = ReconstructionModel(encoder, modeler, renderer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723c3840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_state_dict(f):\n",
    "    state_dict = torch.load(f, weights_only=False).state_dict()\n",
    "    model.modeler.load_state_dict(state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca3b6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_from_scene(scene_data: SceneData):\n",
    "    mask = (scene_data.mask * scene_data.scene.layer.object.appearance.confidence[:, None, ..., 0]).round()\n",
    "    return mask\n",
    "\n",
    "def scene_to_index(scene_data: SceneData):\n",
    "    mask = mask_from_scene(scene_data)\n",
    "    mask = torch.logical_and(mask, (mask.sum(-1, keepdim=True) == 1))\n",
    "    indices = torch.argsort(mask.flatten(1, 2).sum(1)[:, None, None].expand_as(mask), dim=-1, descending=True)\n",
    "    sorted_tensor = torch.gather(mask, -1, indices)\n",
    "    mask_max_values, mask_max_indices = torch.max(sorted_tensor, dim=-1)\n",
    "    mask_max_indices[mask_max_values == 0] = -1\n",
    "    mask_max_indices += 1\n",
    "    return mask_max_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d4cdc1",
   "metadata": {},
   "source": [
    "# Ablations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aa65fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func_image = CombinedLoss((0.01, EfdRegularizerLoss()), (1.0, ImageMaeLoss())).to(device)\n",
    "\n",
    "test_mae = ImageMaeLoss().to(device)\n",
    "test_mse = ImageMseLoss().to(device)\n",
    "test_loss_fn_scene = SceneLoss().to(device)\n",
    "test_ssim = StructuralSimilarityIndexMeasure(data_range=(0.0, 1.0)).to(device)\n",
    "test_iou = BinaryJaccardIndex().to(device)\n",
    "test_ari = MeanMetric()\n",
    "\n",
    "for j, (random, target) in enumerate(epoch_bar := tqdm(zip(val_dataloader, test_dataloader), desc=\"Epoch\")):\n",
    "    pred = random.clone().to(device)\n",
    "    target = target.clone().to(device)\n",
    "\n",
    "    on = j % 4 + 1\n",
    "    f = torch.tensor([1.0] * on + [0.0] * (4 - on), device=device)[None, None, :, None]\n",
    "    pred.scene.layer.object.appearance.confidence[:] = f\n",
    "    target.scene.layer.object.appearance.confidence[:] = f\n",
    "    pred = renderer.render(pred.scene)\n",
    "    target = renderer.render(target.scene)\n",
    "\n",
    "    optimize_params(lambda: pred, target, renderer=renderer, params=pred.scene.fields[\"tsrcb\"], epochs=250, loss_func=loss_func_image, lr=0.01)\n",
    "    optimize_params(lambda: pred, target, renderer=renderer, params=pred.scene.fields[\"tsrcbe\"], epochs=250, loss_func=loss_func_image, lr=0.001)\n",
    "    pred = renderer.render(pred.scene)\n",
    "\n",
    "    img_grid = make_img_grid([target.image_rgb_top, pred.image_rgb_top], padding=2, pad_value=1)\n",
    "    display_img(img_grid)\n",
    "\n",
    "    test_mae(target, pred)\n",
    "    test_mse(target, pred)\n",
    "    test_loss_fn_scene(target, pred)\n",
    "    test_ssim(target.image_rgb.permute(0, 3, 1, 2), pred.image_rgb.permute(0, 3, 1, 2))\n",
    "    test_iou.update(mask_from_scene(target).any(dim=-1, keepdim=True), mask_from_scene(pred).any(dim=-1, keepdim=True))\n",
    "    test_ari.update(ari(scene_to_index(target).cpu(), scene_to_index(pred).cpu(), num_ignored_objects=0).mean())\n",
    "\n",
    "test_mae.show()\n",
    "test_mse.show()\n",
    "test_loss_fn_scene.show()\n",
    "print(\"SSIM:\", test_ssim.compute().item())\n",
    "print(\"IoU:\", test_iou.compute().item())\n",
    "print(\"ARI:\", test_ari.compute().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1d07e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_state_dict(\"./TI-TP/model_X.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0022bca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func_image = ImageMaeLoss().to(device)\n",
    "\n",
    "test_mae = ImageMaeLoss().to(device)\n",
    "test_mse = ImageMseLoss().to(device)\n",
    "test_loss_fn_scene = SceneLoss().to(device)\n",
    "test_ssim = StructuralSimilarityIndexMeasure(data_range=(0.0, 1.0)).to(device)\n",
    "test_iou = BinaryJaccardIndex().to(device)\n",
    "test_ari = MeanMetric()\n",
    "\n",
    "for j, (random, target) in enumerate(epoch_bar := tqdm(zip(val_dataloader, test_dataloader), desc=\"Epoch\")):\n",
    "    pred = random.clone().to(device)\n",
    "    target = target.clone().to(device)\n",
    "\n",
    "    on = j % 4 + 1\n",
    "    f = torch.tensor([1.0] * on + [0.0] * (4 - on), device=device)[None, None, :, None]\n",
    "    pred.scene.layer.object.appearance.confidence[:] = f\n",
    "    target.scene.layer.object.appearance.confidence[:] = f\n",
    "    pred = renderer.render(pred.scene)\n",
    "    target = renderer.render(target.scene)\n",
    "    \n",
    "    latent = encoder(pred.image_rgb)\n",
    "    z = modeler(latent, return_z=True)\n",
    "    z = z.detach()\n",
    "    pred = renderer.render(modeler(latent, custom_z=z))\n",
    "    \n",
    "    optimize_params(lambda: renderer.render(modeler(latent, custom_z=z)), target, renderer=renderer, params=[z], epochs=250, loss_func=loss_func_image, lr=0.01, show_progress=False)\n",
    "    optimize_params(lambda: renderer.render(modeler(latent, custom_z=z)), target, renderer=renderer, params=[z], epochs=250, loss_func=loss_func_image, lr=0.001, show_progress=False)\n",
    "    pred = renderer.render(modeler(latent, custom_z=z))\n",
    "    \n",
    "    test_mae(target, pred)\n",
    "    test_mse(target, pred)\n",
    "    test_loss_fn_scene(target, pred)\n",
    "    test_ssim(target.image_rgb.permute(0, 3, 1, 2), pred.image_rgb.permute(0, 3, 1, 2))\n",
    "    test_iou.update(mask_from_scene(target).any(dim=-1, keepdim=True), mask_from_scene(pred).any(dim=-1, keepdim=True))\n",
    "    test_ari.update(ari(scene_to_index(target).cpu(), scene_to_index(pred).cpu(), num_ignored_objects=0).mean())\n",
    "\n",
    "test_mae.show()\n",
    "test_mse.show()\n",
    "test_loss_fn_scene.show()\n",
    "print(\"SSIM:\", test_ssim.compute().item())\n",
    "print(\"IoU:\", test_iou.compute().item())\n",
    "print(\"ARI:\", test_ari.compute().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2649445e",
   "metadata": {},
   "source": [
    "# Main results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d01326",
   "metadata": {},
   "source": [
    "### DVP+GP, DVP+TI, DVP+TP, DVP+GI, DVP+TI+, DVP+TI-TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e277ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mae = ImageMaeLoss().to(device)\n",
    "test_mse = ImageMseLoss().to(device)\n",
    "test_loss_fn_scene = SceneLoss().to(device)\n",
    "test_ssim = StructuralSimilarityIndexMeasure(data_range=(0.0, 1.0)).to(device)\n",
    "test_iou = BinaryJaccardIndex().to(device)\n",
    "test_ari = MeanMetric()\n",
    "\n",
    "\n",
    "names = [\"./GP/model_X.pt\", \"./TI/model_X.pt\", \"./TP/model_X.pt\", \"./GI/model_19.pt\", \"./TI+_2/model_X.pt\", \"./TI-TP/model_X.pt\"]\n",
    "for name in names:\n",
    "    print(\"\\n==========================\")\n",
    "    print(\">\", name)\n",
    "    print(\"==========================\")\n",
    "    load_state_dict(name)\n",
    "    modeler.eval()\n",
    "    with torch.inference_mode():\n",
    "        test_mae.reset()\n",
    "        test_mse.reset()\n",
    "        test_loss_fn_scene.reset()\n",
    "        test_ssim.reset()\n",
    "        test_iou.reset()\n",
    "        test_ari.reset()\n",
    "        for j, target in enumerate(epoch_bar := tqdm(test_dataloader, desc=\"Epoch\")):\n",
    "            target: SceneData = target.to(device)\n",
    "            target = renderer.render(target.scene)\n",
    "            pred: SceneData = renderer.render(model(target.image_rgb, render=False).scene)\n",
    "            \n",
    "            test_mae(target, pred)\n",
    "            test_mse(target, pred)\n",
    "            test_loss_fn_scene(target, pred)\n",
    "            test_ssim(target.image_rgb.permute(0, 3, 1, 2), pred.image_rgb.permute(0, 3, 1, 2))\n",
    "            test_iou.update(mask_from_scene(target).any(dim=-1, keepdim=True), mask_from_scene(pred).any(dim=-1, keepdim=True))\n",
    "            test_ari.update(ari(scene_to_index(target).cpu(), scene_to_index(pred).cpu(), num_ignored_objects=0).mean())\n",
    "            \n",
    "            epoch_bar.set_postfix({\"mae\": str(test_mae), \"scene\": str(test_loss_fn_scene)})\n",
    "        test_mae.show()\n",
    "        test_mse.show()\n",
    "        test_loss_fn_scene.show()\n",
    "        print(\"SSIM:\", test_ssim.compute().item())\n",
    "        print(\"IoU:\", test_iou.compute().item())\n",
    "        print(\"ARI:\", test_ari.compute().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff1466b",
   "metadata": {},
   "source": [
    "### DVP+TI-TP-OptP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267b89cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mae = ImageMaeLoss().to(device)\n",
    "test_mse = ImageMseLoss().to(device)\n",
    "test_loss_fn_scene = SceneLoss().to(device)\n",
    "test_ssim = StructuralSimilarityIndexMeasure(data_range=(0.0, 1.0)).to(device)\n",
    "test_iou = BinaryJaccardIndex().to(device)\n",
    "test_ari = MeanMetric()\n",
    "\n",
    "\n",
    "names = [\"./TI-TP/model_X.pt\"]\n",
    "for name in names:\n",
    "    print(\"\\n==========================\")\n",
    "    print(\">\", name)\n",
    "    print(\"==========================\")\n",
    "    load_state_dict(name)\n",
    "    modeler.eval()\n",
    "    with nullcontext():\n",
    "        test_mae.reset()\n",
    "        test_mse.reset()\n",
    "        test_loss_fn_scene.reset()\n",
    "        test_ssim.reset()\n",
    "        test_iou.reset()\n",
    "        test_ari.reset()\n",
    "        for j, target in enumerate(epoch_bar := tqdm(test_dataloader, desc=\"Epoch\")):\n",
    "            target: SceneData = target.to(device)\n",
    "            with torch.no_grad():\n",
    "                target = renderer.render(target.scene)\n",
    "                pred: SceneData = renderer.render(model(target.image_rgb, render=False).scene)\n",
    "            \n",
    "            loss_func_image = ImageMaeLoss().to(device)\n",
    "            pred = pred.clone()\n",
    "            optimize_params(pred, target, renderer=renderer, params=pred.scene.fields[\"tsrcb\"], epochs=100, loss_func=loss_func_image, lr=0.01)\n",
    "            pred = renderer.render(pred.scene)\n",
    "            \n",
    "            test_mae(target, pred)\n",
    "            test_mse(target, pred)\n",
    "            test_loss_fn_scene(target, pred)\n",
    "            test_ssim(target.image_rgb.permute(0, 3, 1, 2), pred.image_rgb.permute(0, 3, 1, 2))\n",
    "            test_iou.update(mask_from_scene(target).any(dim=-1, keepdim=True), mask_from_scene(pred).any(dim=-1, keepdim=True))\n",
    "            test_ari.update(ari(scene_to_index(target).cpu(), scene_to_index(pred).cpu(), num_ignored_objects=0).mean())\n",
    "            \n",
    "            epoch_bar.set_postfix({\"mae\": str(test_mae), \"scene\": str(test_loss_fn_scene)})\n",
    "        test_mae.show()\n",
    "        test_mse.show()\n",
    "        test_loss_fn_scene.show()\n",
    "        print(\"SSIM:\", test_ssim.compute().item())\n",
    "        print(\"IoU:\", test_iou.compute().item())\n",
    "        print(\"ARI:\", test_ari.compute().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22b21c2",
   "metadata": {},
   "source": [
    "### DVP+TI-TP-OptZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f316368",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mae = ImageMaeLoss().to(device)\n",
    "test_mse = ImageMseLoss().to(device)\n",
    "test_loss_fn_scene = SceneLoss().to(device)\n",
    "test_ssim = StructuralSimilarityIndexMeasure(data_range=(0.0, 1.0)).to(device)\n",
    "test_iou = BinaryJaccardIndex().to(device)\n",
    "test_ari = MeanMetric()\n",
    "\n",
    "loss_func_image = ImageMaeLoss().to(device)\n",
    "\n",
    "names = [\"./TP_TI_2/model_98.pt\"]\n",
    "for name in names:\n",
    "    print(\"\\n==========================\")\n",
    "    print(\">\", name)\n",
    "    print(\"==========================\")\n",
    "    load_state_dict(name)\n",
    "    modeler.eval()\n",
    "    with nullcontext():\n",
    "        test_mae.reset()\n",
    "        test_mse.reset()\n",
    "        test_loss_fn_scene.reset()\n",
    "        test_ssim.reset()\n",
    "        test_iou.reset()\n",
    "        test_ari.reset()\n",
    "        for j, target in enumerate(epoch_bar := tqdm(test_dataloader, desc=\"Epoch\")):\n",
    "            target: SceneData = target.to(device)\n",
    "            with torch.no_grad():\n",
    "                target = renderer.render(target.scene)\n",
    "                latent = encoder(target.image_rgb)\n",
    "                z = modeler(latent, return_z=True)\n",
    "                pred = renderer.render(modeler(latent, custom_z=z))\n",
    "            \n",
    "            pred = pred.clone() \n",
    "            optimize_params(lambda: renderer.render(modeler(latent, custom_z=z)), target, renderer=renderer, params=[z], epochs=100, loss_func=loss_func_image, lr=0.01, show_progress=False)\n",
    "            pred = renderer.render(modeler(latent, custom_z=z))\n",
    "            \n",
    "            test_mae(target, pred)\n",
    "            test_mse(target, pred)\n",
    "            test_loss_fn_scene(target, pred)\n",
    "            test_ssim(target.image_rgb.permute(0, 3, 1, 2), pred.image_rgb.permute(0, 3, 1, 2))\n",
    "            test_iou.update(mask_from_scene(target).any(dim=-1, keepdim=True), mask_from_scene(pred).any(dim=-1, keepdim=True))\n",
    "            test_ari.update(ari(scene_to_index(target).cpu(), scene_to_index(pred).cpu(), num_ignored_objects=0).mean())\n",
    "            \n",
    "            epoch_bar.set_postfix({\"mae\": str(test_mae), \"scene\": str(test_loss_fn_scene)})\n",
    "        test_mae.show()\n",
    "        test_mse.show()\n",
    "        test_loss_fn_scene.show()\n",
    "        print(\"SSIM:\", test_ssim.compute().item())\n",
    "        print(\"IoU:\", test_iou.compute().item())\n",
    "        print(\"ARI:\", test_ari.compute().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78967f33",
   "metadata": {},
   "source": [
    "### MONet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422d6b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./object_centric_library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2275ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_centric_library.models.monet.model import Monet\n",
    "from object_centric_library.utils.viz import make_recon_img\n",
    "\n",
    "\n",
    "width, height = 128, 128\n",
    "monet_config = OmegaConf.load(\"./object_centric_library/config/model/monet.yaml\").model\n",
    "\n",
    "monet_config.num_slots = 5\n",
    "monet_config.decoder_params.w_broadcast = width + 8\n",
    "monet_config.decoder_params.h_broadcast = height + 8\n",
    "monet_config.num_blocks_unet = 6\n",
    "del monet_config[\"_target_\"]\n",
    "\n",
    "model_monet = Monet(**monet_config, width=width, height=height).to(device)\n",
    "state_dict = torch.load(\"./MONET/model_X.pt\", weights_only=False).state_dict()\n",
    "model_monet.load_state_dict(state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5b5016",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mae = ImageMaeLoss().to(device)\n",
    "test_mse = ImageMseLoss().to(device)\n",
    "test_loss_fn_scene = SceneLoss().to(device)\n",
    "test_ssim = StructuralSimilarityIndexMeasure(data_range=(0.0, 1.0)).to(device)\n",
    "test_iou = BinaryJaccardIndex().to(device)\n",
    "test_ari = MeanMetric()\n",
    "\n",
    "\n",
    "names = [\"MONet\"]\n",
    "for name in names:\n",
    "    print(\"\\n==========================\")\n",
    "    print(\">\", name)\n",
    "    print(\"==========================\")\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        test_mae.reset()\n",
    "        test_mse.reset()\n",
    "        test_loss_fn_scene.reset()\n",
    "        test_ssim.reset()\n",
    "        test_iou.reset()\n",
    "        test_ari.reset()\n",
    "        for j, target in enumerate(epoch_bar := tqdm(test_dataloader, desc=\"Epoch\")):\n",
    "            target: SceneData = target.to(device)\n",
    "            target = renderer.render(target.scene)\n",
    "            \n",
    "            pred = model_monet(target.image_rgb.permute(0, 3, 1, 2))\n",
    "            pred_img = make_recon_img(pred[\"slot\"], pred[\"mask\"]).permute(0, 2, 3, 1)\n",
    "            pred_mask = pred[\"mask\"] \n",
    "            pred = SceneData(image=pred_img, batch_size=[batch_size])\n",
    "\n",
    "            test_mae(target, pred)\n",
    "            test_mse(target, pred)\n",
    "\n",
    "            test_ssim(target.image_rgb.permute(0, 3, 1, 2), pred.image_rgb.permute(0, 3, 1, 2))\n",
    "            \n",
    "            mask = pred_mask.permute(0, 3, 4, 2, 1).flatten(-2, -1)[..., 1:].round()\n",
    "            test_iou.update(mask_from_scene(target).any(dim=-1, keepdim=True), mask.any(dim=-1, keepdim=True))\n",
    "            \n",
    "            mask = torch.logical_and(mask, (mask.sum(-1, keepdim=True) == 1))\n",
    "            indices = torch.argsort(mask.flatten(1, 2).sum(1)[:, None, None].expand_as(mask), dim=-1, descending=True)\n",
    "            sorted_tensor = torch.gather(mask, -1, indices)\n",
    "            mask_max_values, mask_max_indices = torch.max(sorted_tensor, dim=-1)\n",
    "            mask_max_indices[mask_max_values == 0] = -1\n",
    "            mask_max_indices += 1\n",
    "            test_ari.update(ari(scene_to_index(target).cpu(), mask_max_indices.cpu(), num_ignored_objects=0).mean())\n",
    "            \n",
    "            epoch_bar.set_postfix({\"mae\": str(test_mae)})\n",
    "            \n",
    "        test_mae.show()\n",
    "        test_mse.show()\n",
    "        test_loss_fn_scene.show()\n",
    "        print(\"SSIM:\", test_ssim.compute().item())\n",
    "        print(\"IoU:\", test_iou.compute().item())\n",
    "        print(\"ARI:\", test_ari.compute().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ccc6a6",
   "metadata": {},
   "source": [
    "### Opt-Iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1204916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OptIter_object_init(pred, target):\n",
    "    device = pred.device\n",
    "    \n",
    "    no_diff_thresh = 0.01\n",
    "    quantile_interval = 100\n",
    "    map = l1_loss(pred, target, reduction=\"none\").mean(dim=-1, keepdim=True)\n",
    "    map[map < no_diff_thresh] = 0\n",
    "    bin_label = (map * quantile_interval).to(torch.uint8)\n",
    "    \n",
    "    def best_label(bin_labels):\n",
    "        blobs_labels = measure.label(bin_labels, background=0)\n",
    "        count = np.bincount(blobs_labels.flatten(), weights=bin_labels.flatten())\n",
    "        mask = blobs_labels == np.argmax(count)\n",
    "\n",
    "        props = measure.regionprops(mask.squeeze(-1).astype(np.uint8))\n",
    "        angle = props[0].orientation\n",
    "        return mask, np.array([np.cos(angle), np.sin(angle)])\n",
    "        \n",
    "    \n",
    "    blobs_mask, rotation_vec = (torch.from_numpy(x).to(device) for x in np.vectorize(best_label, signature='(w,h,c)->(w,h,c),(n)')(bin_label.cpu()))\n",
    "        \n",
    "    xs = torch.linspace(0, 1, steps=raster_size[0], device=device)\n",
    "    ys = torch.linspace(0, 1, steps=raster_size[1], device=device)\n",
    "    xy = torch.roll(torch.cartesian_prod(ys, xs).view(1, *raster_size, 2), 1, dims=-1)\n",
    "    xy_masked = (xy * (blobs_mask / blobs_mask)).flatten(1, 2)\n",
    "    centroid = xy_masked.nanmean(dim=1, keepdim=True)\n",
    "    idx = torch.pow(xy_masked - centroid, 2).sum(dim=-1, keepdim=True).nan_to_num(torch.inf).argmin(dim=1, keepdim=True)\n",
    "    translation = torch.gather(xy_masked, 1, idx.expand((-1, -1, 2)))[:, 0]\n",
    "    color = (target * (blobs_mask / blobs_mask)).nanmean(dim=(1, 2))\n",
    "    return translation, color, rotation_vec\n",
    "\n",
    "def OptIter(target, object_size=4):\n",
    "    device = target.image_rgb.device\n",
    "    batch_size = target.shape[0]\n",
    "    layer_size = 1\n",
    "    efd_size = 16\n",
    "    translation = torch.zeros((batch_size, layer_size, object_size, 2), dtype=torch.float32)\n",
    "    scale = torch.ones((batch_size, layer_size, object_size, 2), dtype=torch.float32)\n",
    "    color = torch.zeros((batch_size, layer_size, object_size, 3), dtype=torch.float32)\n",
    "    confidence = torch.zeros((batch_size, layer_size, object_size, 1), dtype=torch.float32)\n",
    "    rotation_vec = torch.ones((batch_size, layer_size, object_size, 2), dtype=torch.float32)\n",
    "    objectShape = torch.ones((batch_size, layer_size, object_size, 1), dtype=torch.uint8) * Shape2D.EFD_SHAPE.value\n",
    "    efd = ellipse_efd(efd_size, -0.75)[None, None, None].to(device).expand(batch_size, layer_size, object_size, efd_size, 4)\n",
    "    backgroundColor = target.image_rgb.flatten(1, 2).median(dim=1)[0]\n",
    "\n",
    "    pred = SceneData(scene=Scene.from_tensors_sparse(\n",
    "        translation=translation,\n",
    "        scale=scale,\n",
    "        color=color,\n",
    "        confidence=confidence,\n",
    "        rotation_vec=rotation_vec,\n",
    "        objectShape=objectShape,\n",
    "        efd=efd,\n",
    "        backgroundColor=backgroundColor,\n",
    "    ), batch_size=[batch_size]).to(device)\n",
    "\n",
    "    loss_func_image = CombinedLoss((0.01, EfdRegularizerLoss()), (1.0, ImageMaeLoss())).to(device)\n",
    "    pred = renderer.render(pred.scene)\n",
    "\n",
    "    for i in range(object_size):\n",
    "        pred.scene.layer.object.appearance.confidence[:, 0, i] = 1\n",
    "        translation, color, rotation_vec = OptIter_object_init(pred.image_rgb, target.image_rgb)\n",
    "        pred.scene.layer.object.appearance.color[:, 0, i] = color\n",
    "        pred.scene.layer.object.transformation.translation[:, 0, i] = translation\n",
    "        pred.scene.layer.object.transformation.rotation_vec[:, 0, i] = rotation_vec\n",
    "        pred.scene.layer.object.transformation.scale[:, 0, i] = 0.1\n",
    "        \n",
    "        optimize_params(pred, target, renderer=renderer, params=pred.scene.fields[\"tsrcb\"], epochs=100, loss_func=loss_func_image, lr=0.01)\n",
    "        optimize_params(pred, target, renderer=renderer, params=pred.scene.fields[\"tsrcbe\"], epochs=400, loss_func=loss_func_image, lr=0.0005)\n",
    "        pred = renderer.render(pred.scene)\n",
    "        \n",
    "    optimize_params(pred, target, renderer=renderer, params=pred.scene.fields[\"tsrcbe\"], epochs=100, loss_func=loss_func_image, lr=0.0005)\n",
    "    pred = renderer.render(pred.scene)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155b0066",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mae = ImageMaeLoss().to(device)\n",
    "test_mse = ImageMseLoss().to(device)\n",
    "test_loss_fn_scene = SceneLoss().to(device)\n",
    "test_ssim = StructuralSimilarityIndexMeasure(data_range=(0.0, 1.0)).to(device)\n",
    "test_iou = BinaryJaccardIndex().to(device)\n",
    "test_ari = MeanMetric()\n",
    "\n",
    "names = [\"Opt-Iter\"]\n",
    "for name in names:\n",
    "    print(\"\\n==========================\")\n",
    "    print(\">\", name)\n",
    "    print(\"==========================\")\n",
    "    test_mae.reset()\n",
    "    test_mse.reset()\n",
    "    test_loss_fn_scene.reset()\n",
    "    test_ssim.reset()\n",
    "    test_iou.reset()\n",
    "    test_ari.reset()\n",
    "    for j, target in enumerate(epoch_bar := tqdm(test_dataloader, desc=\"Epoch\")):\n",
    "        target: SceneData = target.to(device)\n",
    "        target = renderer.render(target.scene)\n",
    "        pred: SceneData = OptIter(target)\n",
    "        \n",
    "        test_mae(target, pred)\n",
    "        test_mse(target, pred)\n",
    "        test_loss_fn_scene(target, pred)\n",
    "        test_ssim(target.image_rgb.permute(0, 3, 1, 2), pred.image_rgb.permute(0, 3, 1, 2))\n",
    "        test_iou.update(mask_from_scene(target).any(dim=-1, keepdim=True), mask_from_scene(pred).any(dim=-1, keepdim=True))\n",
    "        test_ari.update(ari(scene_to_index(target).cpu(), scene_to_index(pred).cpu(), num_ignored_objects=0).mean())\n",
    "        \n",
    "        epoch_bar.set_postfix({\"mae\": str(test_mae), \"scene\": str(test_loss_fn_scene)})\n",
    "        \n",
    "    test_mae.show()\n",
    "    test_mse.show()\n",
    "    test_loss_fn_scene.show()\n",
    "    print(\"SSIM:\", test_ssim.compute().item())\n",
    "    print(\"IoU:\", test_iou.compute().item())\n",
    "    print(\"ARI:\", test_ari.compute().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabf3532",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mae = ImageMaeLoss().to(device)\n",
    "test_mse = ImageMseLoss().to(device)\n",
    "test_loss_fn_scene = SceneLoss().to(device)\n",
    "test_ssim = StructuralSimilarityIndexMeasure(data_range=(0.0, 1.0)).to(device)\n",
    "test_iou = BinaryJaccardIndex().to(device)\n",
    "test_ari = MeanMetric()\n",
    "\n",
    "names = [\"LIVE\"]\n",
    "for name in names:\n",
    "    print(\"\\n==========================\")\n",
    "    print(\">\", name)\n",
    "    print(\"==========================\")\n",
    "    test_mae.reset()\n",
    "    test_mse.reset()\n",
    "    test_loss_fn_scene.reset()\n",
    "    test_ssim.reset()\n",
    "    test_iou.reset()\n",
    "    test_ari.reset()\n",
    "    for k, target in zip(range(64), val_dataset):\n",
    "        \n",
    "        path = glob(f\"./LIVE-Layerwise-Image-Vectorization/LIVE/val_dataset_log/*_{k}\")[0]\n",
    "        with open(f\"{path}/output-svg/1-1-1-1-1.svg\") as fp:\n",
    "            soup = BeautifulSoup(fp, 'xml')\n",
    "            \n",
    "        pred = Image.open(BytesIO(cairosvg.svg2png(bytestring=soup.prettify(), background_color='white', output_width=raster_size[0], output_height=raster_size[1])))\n",
    "        pred = pil_to_tensor(pred).permute(1, 2, 0)[None] / 255\n",
    "        pred = SceneData(image=pred, batch_size=[1])\n",
    "        \n",
    "        test_mae(target, pred)\n",
    "        test_mse(target, pred)\n",
    "        test_ssim(target.image_rgb.permute(0, 3, 1, 2), pred.image_rgb.permute(0, 3, 1, 2))\n",
    "        \n",
    "        masks = []\n",
    "        \n",
    "        for i in range(5):\n",
    "            soup_copy = copy.copy(soup)\n",
    "            for j, path in enumerate(soup_copy.find_all(\"path\")):\n",
    "                if i != j:\n",
    "                    path.decompose()\n",
    "                else:\n",
    "                    path[\"fill\"] = \"rgb(255, 255, 255)\"\n",
    "\n",
    "            svg_raster_bytes = cairosvg.svg2png(bytestring=soup_copy.prettify(), background_color='black', output_width=raster_size[0], output_height=raster_size[1]) \n",
    "            svg_raster = Image.open(BytesIO(svg_raster_bytes))\n",
    "            \n",
    "            mask = pil_to_tensor(svg_raster).permute(1, 2, 0)[None, ..., 0, None] / 255\n",
    "            if (mask.sum() + 0.5).round() > 128*128 * 0.5:\n",
    "                mask = 1 - mask\n",
    "            masks.append(mask)\n",
    "        \n",
    "        background_idx = min(enumerate([mask.round().sum() for mask in masks]), key=lambda x: x[1])[0]\n",
    "        \n",
    "        del masks[background_idx]\n",
    "        \n",
    "        target: SceneData = target.to(device)\n",
    "        target = renderer.render(target.scene).cpu()\n",
    "        \n",
    "        test_iou.update(mask_from_scene(target).any(dim=-1, keepdim=True).cpu(), torch.cat(masks, dim=-1).round().any(dim=-1, keepdim=True).cpu())\n",
    "        \n",
    "        \n",
    "        def scene_to_index2():\n",
    "            mask = torch.cat(masks, dim=-1).round()\n",
    "            mask = torch.logical_and(mask, (mask.sum(-1, keepdim=True) == 1))\n",
    "            indices = torch.argsort(mask.flatten(1, 2).sum(1)[:, None, None].expand_as(mask), dim=-1, descending=True)\n",
    "            sorted_tensor = torch.gather(mask, -1, indices)\n",
    "            mask_max_values, mask_max_indices = torch.max(sorted_tensor, dim=-1)\n",
    "            mask_max_indices[mask_max_values == 0] = -1\n",
    "            mask_max_indices += 1\n",
    "            return mask_max_indices\n",
    "        \n",
    "        test_ari.update(ari(scene_to_index(target).cpu(), scene_to_index2().cpu(), num_ignored_objects=0).mean())\n",
    "        \n",
    "    test_mae.show()\n",
    "    test_mse.show()\n",
    "    test_loss_fn_scene.show()\n",
    "    print(\"SSIM:\", test_ssim.compute().item())\n",
    "    print(\"IoU:\", test_iou.compute().item())\n",
    "    print(\"ARI:\", test_ari.compute().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a060de6",
   "metadata": {},
   "source": [
    "# Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c2d8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_pairs(iterable):\n",
    "    it = iter(iterable)\n",
    "    while True:\n",
    "        try:\n",
    "            yield next(it), next(it)\n",
    "        except StopIteration:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d836042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func_scene = SceneLoss().to(device)\n",
    "\n",
    "# INSTRUCTION\n",
    "# Run this and next 3 cells, to collect results for MAE\n",
    "# Then uncomment disabled MSE lines, comment lines corresponding to MAE, and collect results for MSE\n",
    "\n",
    "loss_func_image = ImageMaeLoss().to(device)\n",
    "# loss_func_image = ImageMseLoss().to(device)\n",
    "\n",
    "ws = [0.05] + np.linspace(0.1, 1.0, 10).tolist()\n",
    "\n",
    "global_metric_dict = dict()\n",
    "for w in ws:\n",
    "    metric_dict = defaultdict(MeanMetric)\n",
    "\n",
    "    for i, (a, b) in enumerate(iterate_pairs(tqdm(train_dataloader))):\n",
    "        if i == 16:\n",
    "            break\n",
    "        \n",
    "        a = a.to(device)\n",
    "        b = b.to(device)\n",
    "        \n",
    "        a = renderer.render(a.scene)\n",
    "\n",
    "        ab: Scene = Scene.interpolate(a.scene, b.scene, weight=w).to(device)\n",
    "        ab.fields[\"f\"][:] = torch.round(ab.fields[\"f\"][:])\n",
    "\n",
    "        names = \"tsrceb\"\n",
    "        fields = ab.fields[names]\n",
    "        for f in fields:\n",
    "            f.requires_grad = True\n",
    "\n",
    "\n",
    "        ab = renderer.render(ab)\n",
    "\n",
    "        grad_scene = torch.autograd.grad(loss_func_scene(a, ab), fields)\n",
    "        grad_mse = torch.autograd.grad(loss_func_image(a, ab), fields)\n",
    "\n",
    "        for n, g1, g2 in zip(names, grad_scene, grad_mse):\n",
    "            if n == \"e\":\n",
    "                g1 = g1.flatten(-2, -1)\n",
    "                g2 = g2.flatten(-2, -1)\n",
    "            if n == \"s\":\n",
    "                g1 = g1[..., 0, None]\n",
    "                g2 = g2[..., 0, None]\n",
    "\n",
    "            sim = torch.nn.functional.cosine_similarity(g1, g2, dim=-1)\n",
    "\n",
    "            metric_dict[n].update(sim.mean().detach().cpu())\n",
    "\n",
    "    for n in metric_dict.keys():\n",
    "        metric_dict[n] = metric_dict[n].compute().item()\n",
    "    global_metric_dict[w] = metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3408896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(global_metric_dict).transpose()\n",
    "df = pd.melt(df, var_name=\"property\", ignore_index=False)\n",
    "df = df.reset_index(names=[\"t\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f0407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_df = df\n",
    "mae_df[\"loss\"] = \"MAE\"\n",
    "# mse_df = df\n",
    "# mse_df[\"loss\"] = \"MSE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cff2d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([mse_df, mae_df])\n",
    "df.to_csv(\"gradient.csv\", sep='\\t', encoding='utf-8', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75965cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.set_context(\"notebook\")\n",
    "pd.set_option(\"display.max_colwidth\", 100)\n",
    "matplotlib.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "matplotlib.rcParams[\"axes.formatter.use_mathtext\"] = True\n",
    "matplotlib.rcParams.update({\"font.size\": 36})\n",
    "matplotlib.rcParams.update({'text.usetex': True, })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7ff365",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE = 15\n",
    "MEDIUM_SIZE = 15\n",
    "BIGGER_SIZE = 15\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118eb14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./gradient.csv\", sep=\"\\t\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeffb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "\n",
    "font_path = \"Times New Roman.ttf\"\n",
    "font_manager.fontManager.addfont(font_path)\n",
    "prop = font_manager.FontProperties(fname=font_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0f3dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gcf().set_size_inches(5, 3.5)\n",
    "sns.lineplot(data=df, x=\"Noise strength\", y=\"Cosine simmilarity\", hue=\"Property\", style=\"Loss\")\n",
    "\n",
    "plt.gca().set_xlabel('$\\\\alpha$', fontsize=16)\n",
    "plt.legend(ncol=1, loc=\"center right\", bbox_to_anchor=(1.5, 0.46))\n",
    "plt.savefig(\"gradient.pdf\", bbox_inches=\"tight\", pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e6a8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_pairs(iterable):\n",
    "    it = iter(iterable)\n",
    "    while True:\n",
    "        try:\n",
    "            yield next(it), next(it)\n",
    "        except StopIteration:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dca5f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func_scene = SceneLoss().to(device)\n",
    "loss_func_image = ImageMaeLoss().to(device)\n",
    "\n",
    "ws = [0.05] + np.linspace(0.1, 1.0, 10).tolist()\n",
    "\n",
    "global_list = list()\n",
    "\n",
    "for w in ws:\n",
    "    unoptimized = MeanMetric().to(device)\n",
    "    optimized = MeanMetric().to(device)\n",
    "    \n",
    "    for i, (a, b) in enumerate(iterate_pairs(tqdm(train_dataloader))):\n",
    "        if i == 16:\n",
    "            break\n",
    "        \n",
    "        a: SceneData = renderer.render(a.to(device).scene)\n",
    "        b: SceneData = b.to(device)\n",
    "\n",
    "        ab: Scene = Scene.interpolate(a.scene, b.scene, weight=w).to(device)\n",
    "        ab.fields[\"f\"][:] = torch.round(ab.fields[\"f\"][:])\n",
    "        ab: SceneData = renderer.render(ab)\n",
    "\n",
    "        optimize_params(ab, a, renderer=renderer, params=ab.scene.fields[\"tsrcb\"], epochs=25, loss_func=loss_func_image, lr=0.01)\n",
    "        optimize_params(ab, a, renderer=renderer, params=[ab.scene.fields[\"e\"]], epochs=25, loss_func=loss_func_image, lr=0.001)\n",
    "        optimize_params(ab, a, renderer=renderer, params=ab.scene.fields[\"tsrcbe\"], epochs=50, loss_func=loss_func_image, lr=0.001)\n",
    "        ab_optimized = renderer.render(ab.scene)\n",
    "\n",
    "        mse1 = mse_loss(a.image_rgb, ab.image_rgb).reshape(1)\n",
    "        mse2 = mse_loss(a.image_rgb, ab_optimized.image_rgb).reshape(1)\n",
    "        \n",
    "        unoptimized.update(mse1)\n",
    "        optimized.update(mse2)\n",
    "        \n",
    "    global_list.append(dict(t=w, unoptimized=unoptimized.compute().item(), optimized=optimized.compute().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a4bac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(global_list)\n",
    "df.to_csv(\"optimized.csv\", sep='\\t', encoding='utf-8', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97ccb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./optimized.csv\", sep=\"\\t\")\n",
    "df = df.set_index(\"Noise strength\")\n",
    "df = pd.melt(df, var_name=\" \", value_name=\"MAE\", ignore_index=False)\n",
    "df = df.reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea21d67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gcf().set_size_inches(5, 3.5)\n",
    "sns.lineplot(df, x=\"Noise strength\", y=\"MAE\", hue=\" \")\n",
    "\n",
    "T = plt.legend().get_texts()\n",
    "T[0].set_text('before optimization')\n",
    "T[1].set_text('after optimization')\n",
    "plt.gca().set_xlabel('$\\\\alpha$', fontsize=16)\n",
    "plt.savefig(\"optimized.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d57e6c",
   "metadata": {},
   "source": [
    "# Overlapping objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab24794",
   "metadata": {},
   "outputs": [],
   "source": [
    "opengl_renderer = OpenGLRenderer2D(raster_size, contours_only=True, background_color=colors.white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcd38ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_state_dict(\"./TI-TP/model_X.pt\")\n",
    "\n",
    "img_grids = []\n",
    "for d in [0.15, 0.1, 0.05]:\n",
    "    target = next(iter(val_dataloader))[4:6].clone().to(device)\n",
    "\n",
    "    target.scene.fields[\"t\"][:] = 0.5\n",
    "    target.scene.fields[\"s\"][:] = 0.1\n",
    "    target.scene.fields[\"r\"][..., 0] = -1\n",
    "    target.scene.fields[\"r\"][..., 1] = 0\n",
    "    target.scene.fields[\"r\"][..., 1, 0] = 1\n",
    "    target.scene.fields[\"f\"][..., :2, :] = 1\n",
    "    target.scene.fields[\"c\"][..., 0, :] = target.scene.fields[\"c\"][..., 1, :]\n",
    "    target.scene.fields[\"e\"][..., 1, :, :] = target.scene.fields[\"e\"][..., 0, :, :]\n",
    "    target.scene.fields[\"t\"][..., 0, 0] = 0.5 + d\n",
    "    target.scene.fields[\"t\"][..., 1, 0] = 0.5 - d\n",
    "\n",
    "    target = renderer.render(target.scene)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_dvp: SceneData = model(target.image_rgb, render=False)\n",
    "        pred_dvp.scene.fields[\"f\"][:] = pred_dvp.scene.fields[\"f\"].round()\n",
    "        pred_dvp.scene.fields[\"c\"][..., 2, :] = colors.red[:3]\n",
    "        pred_dvp.scene.fields[\"c\"][..., 3, :] = colors.blue[:3]\n",
    "        pred_dvp.scene.fields[\"c\"][..., 4, :] = colors.red[:3]\n",
    "        pred_dvp = opengl_renderer.render(pred_dvp.scene)\n",
    "\n",
    "    pred_live = OptIter(target, object_size=2)\n",
    "    pred_live.scene.fields[\"c\"][..., 0, :] = colors.red[:3]\n",
    "    pred_live.scene.fields[\"c\"][..., 1, :] = colors.blue[:3]\n",
    "    pred_live = opengl_renderer.render(pred_live.scene)\n",
    "\n",
    "    mask = model_monet(target.image_rgb.permute(0, 3, 1, 2))[\"mask\"].detach().permute(0, 3, 4, 2, 1).flatten(-2, -1)[..., 1:].round().cpu()\n",
    "    A = canny(mask[..., 0, None].permute(0, 3, 1, 2), kernel_size=(9, 9))[1].permute(0, 2, 3, 1).to(torch.int32)\n",
    "    B = canny(mask[..., 1, None].permute(0, 3, 1, 2), kernel_size=(9, 9))[1].permute(0, 2, 3, 1).to(torch.int32)\n",
    "    A = torch.tensor([[0, 0, 0], [1, 0, 0]], dtype=torch.float32)[A][..., 0, :]\n",
    "    B = torch.tensor([[0, 0, 0], [0, 0, 1]], dtype=torch.float32)[B][..., 0, :]\n",
    "    AB = A + B\n",
    "    AB[(AB == torch.zeros(3)[None, None, None]).all(dim=-1, keepdim=True).repeat(1, 1, 1, 3)] = 1\n",
    "    AB = gaussian_blur2d(AB.permute(0, 3, 1, 2), (3, 3), (0.5, 0.5)).permute(0, 2, 3, 1)\n",
    "\n",
    "    target.scene.fields[\"c\"][..., 0, :] = colors.red[:3]\n",
    "    target.scene.fields[\"c\"][..., 1, :] = colors.blue[:3]\n",
    "    contours = opengl_renderer.render(target.scene)\n",
    "    img_grid = make_img_grid([target.image_rgb_top.cpu(), contours.image_rgb_top, pred_dvp.image_rgb, pred_live.image_rgb, AB], padding=2, pad_value=1, nrow=10)\n",
    "    img_grids.append(img_grid)\n",
    "    display_img(img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8416876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img(torch.cat([x[2:] for x in img_grids], dim=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
